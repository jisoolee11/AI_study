{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16-CIFAR10(test1).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6ANJn2sPzGYlbRDZuh40D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jisoolee11/AI_study/blob/main/VGG16_CIFAR10(test1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI5kc9i9aKIY"
      },
      "source": [
        "# 라이브러리 불러오기\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcT9F1oalQS",
        "outputId": "06830557-6d14-4fa2-889b-5e84e62980dc"
      },
      "source": [
        "# CIFAR10 불러오고 정규화하기\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "\r\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\r\n",
        "\r\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\r\n",
        "\r\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\r\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwMO_9qkdmRi"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchsummary import summary\r\n",
        "from torchvision.models import vgg16\r\n",
        "\r\n",
        "\r\n",
        "class vgg16(nn.Module):\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        in_channels: int = 3) -> None:\r\n",
        "        super().__init__()\r\n",
        "        self.conv1_1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\r\n",
        "        self.conv1_2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\r\n",
        "\r\n",
        "        self.conv2_1 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\r\n",
        "        self.conv2_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\r\n",
        "\r\n",
        "        self.conv3_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\r\n",
        "        self.conv3_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\r\n",
        "        self.conv3_3 = nn.Conv2d(128, 128, kernel_size=1, padding=1)\r\n",
        "\r\n",
        "        self.conv4_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\r\n",
        "        self.conv4_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\r\n",
        "        self.conv4_3 = nn.Conv2d(256, 256, kernel_size=1, padding=1)\r\n",
        "\r\n",
        "        self.conv5_1 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\r\n",
        "        self.conv5_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\r\n",
        "        self.conv5_3 = nn.Conv2d(256, 256, kernel_size=1, padding=1)\r\n",
        "\r\n",
        "        self.pool = nn.AdaptiveAvgPool2d((2, 2))\r\n",
        "\r\n",
        "        self.fc6 = nn.Linear(in_features=256*2*2, out_features=512)\r\n",
        "        self.fc7 = nn.Linear(in_features=512, out_features=512)\r\n",
        "        self.fc8 = nn.Linear(in_features=512, out_features=10)\r\n",
        "        \r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "      x = F.relu(self.conv1_1(x))\r\n",
        "      x = F.relu(self.conv1_2(x))\r\n",
        "      x = self.pool(x)\r\n",
        "      x = F.relu(self.conv2_1(x))\r\n",
        "      x = F.relu(self.conv2_2(x))\r\n",
        "      x = self.pool(x)\r\n",
        "      x = F.relu(self.conv3_1(x))\r\n",
        "      x = F.relu(self.conv3_2(x))\r\n",
        "      x = F.relu(self.conv3_3(x))\r\n",
        "      x = self.pool(x)\r\n",
        "      x = F.relu(self.conv4_1(x))\r\n",
        "      x = F.relu(self.conv4_2(x))\r\n",
        "      x = F.relu(self.conv4_3(x))\r\n",
        "      x = self.pool(x)\r\n",
        "      x = F.relu(self.conv5_1(x))\r\n",
        "      x = F.relu(self.conv5_2(x))\r\n",
        "      x = F.relu(self.conv5_3(x))\r\n",
        "      x = self.pool(x)\r\n",
        "\r\n",
        "      x = x.view(-1, 2*2*256)\r\n",
        "\r\n",
        "      x = F.relu(self.fc6(x))\r\n",
        "      x = F.relu(self.fc7(x))\r\n",
        "      x = F.relu(self.fc8(x))\r\n",
        "      return x"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVcaWwboiL9b"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "criterion = nn. CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYrp1dVBi_kD",
        "outputId": "36155ab6-ed5f-476c-cd37-b29bde87205e"
      },
      "source": [
        "for epoch in range(2):\r\n",
        "  running_loss = 0.0\r\n",
        "  for i, data in enumerate(trainloader, 0):\r\n",
        "    inputs, labels = data\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    outputs = net(inputs)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    running_loss += loss.item()\r\n",
        "    if i % 2000 == 1999:\r\n",
        "      print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\r\n",
        "      running_loss = 0.0\r\n",
        "\r\n",
        "print('Finished Training')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 0.690\n",
            "[1,  4000] loss: 0.656\n",
            "[1,  6000] loss: 0.638\n",
            "[1,  8000] loss: 0.624\n",
            "[1, 10000] loss: 0.648\n",
            "[1, 12000] loss: 0.641\n",
            "[2,  2000] loss: 0.597\n",
            "[2,  4000] loss: 0.589\n",
            "[2,  6000] loss: 0.606\n",
            "[2,  8000] loss: 0.596\n",
            "[2, 10000] loss: 0.608\n",
            "[2, 12000] loss: 0.600\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYu3K9akzKLB",
        "outputId": "323d4259-ea37-40d2-f8ca-2031287e48c4"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\r\n",
        "class_total = list(0. for i in range(10))\r\n",
        "with torch.no_grad():\r\n",
        "    for data in testloader:\r\n",
        "        images, labels = data\r\n",
        "        outputs = net(images)\r\n",
        "        _, predicted = torch.max(outputs, 1)\r\n",
        "        c = (predicted == labels).squeeze()\r\n",
        "        for i in range(4):\r\n",
        "            label = labels[i]\r\n",
        "            class_correct[label] += c[i].item()\r\n",
        "            class_total[label] += 1\r\n",
        "\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "    print('Accuracy of %5s : %2d %%' % (\r\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 70 %\n",
            "Accuracy of   car : 80 %\n",
            "Accuracy of  bird : 52 %\n",
            "Accuracy of   cat : 45 %\n",
            "Accuracy of  deer : 60 %\n",
            "Accuracy of   dog : 53 %\n",
            "Accuracy of  frog : 76 %\n",
            "Accuracy of horse : 69 %\n",
            "Accuracy of  ship : 74 %\n",
            "Accuracy of truck : 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
