{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn the Basic_Optimization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9a2Z8jv5L6cCpfIGSW3x9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jisoolee11/study/blob/main/pytorch_tutorials/Learn_the_Basic_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTx5icOR8pDl"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cgzHpP-81QY"
      },
      "source": [
        "## Pre-requisite Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAuuvSY-8-O4"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import datasets\r\n",
        "from torchvision.transforms import ToTensor, Lambda\r\n",
        "\r\n",
        "training_data = datasets.FashionMNIST(\r\n",
        "    root=\"data\",\r\n",
        "    train=True,\r\n",
        "    download=True,\r\n",
        "    transform=ToTensor()\r\n",
        ")\r\n",
        "\r\n",
        "test_data = datasets.FashionMNIST(\r\n",
        "    root=\"data\",\r\n",
        "    train=False,\r\n",
        "    download=True,\r\n",
        "    transform=ToTensor()\r\n",
        ")\r\n",
        "\r\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\r\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\r\n",
        "\r\n",
        "class NeuralNetwork(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(NeuralNetwork, self).__init__()\r\n",
        "        self.flatten = nn.Flatten()\r\n",
        "        self.linear_relu_stack = nn.Sequential(\r\n",
        "            nn.Linear(28*28, 512),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(512, 512),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(512, 10),\r\n",
        "            nn.ReLU()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.flatten(x)\r\n",
        "        logits = self.linear_relu_stack(x)\r\n",
        "        return logits\r\n",
        "\r\n",
        "model = NeuralNetwork()\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZMTlDKA_GP7"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iI4TzNr_Vh5"
      },
      "source": [
        "learning_rate = 1e-3\r\n",
        "batch_size = 64\r\n",
        "epochs = 5"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNQTAjVz_mIr"
      },
      "source": [
        "## Optimization Loop\r\n",
        "\r\n",
        "Train Loop: 훈련 데이터셋을 반복하여 최적의 매개변수로 수렴\r\n",
        "\r\n",
        "Validation/Test Loop: 모델 성능 확인을 위해 테스트 데이터셋을 반복"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsag78GMAfOw"
      },
      "source": [
        "# train loop\r\n",
        "# Loss Function\r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Optimizer\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "# optimizer.zero_grad()\r\n",
        "# loss.backwards()\r\n",
        "# optimizer.step()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywN9rAbMBgta"
      },
      "source": [
        "## Full Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzDFg2oCBrf9"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\r\n",
        "    size = len(dataloader.dataset)\r\n",
        "    for batch, (X, y) in enumerate(dataloader):\r\n",
        "        pred = model(X)\r\n",
        "        loss = loss_fn(pred, y)\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if batch % 100 == 0:\r\n",
        "            loss, current = loss.item(), batch * len(X)\r\n",
        "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\r\n",
        "\r\n",
        "def test_loop(dataloader, model, loss_fn):\r\n",
        "    size = len(dataloader.dataset)\r\n",
        "    test_loss, correct = 0, 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for X, y in dataloader:\r\n",
        "            pred = model(X)\r\n",
        "            test_loss += loss_fn(pred, y).item()\r\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\r\n",
        "\r\n",
        "    test_loss /= size\r\n",
        "    correct /= size\r\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83SOGNILDjD4",
        "outputId": "b58b7a01-428f-4f51-bd35-4de6e3e0f89c"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "epochs = 10\r\n",
        "for t in range(epochs):\r\n",
        "    print(f\"Epoch {t+1}\\n--------------------------------\")\r\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\r\n",
        "    test_loop(test_dataloader, model, loss_fn)\r\n",
        "print(\"Done!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "--------------------------------\n",
            "loss: 2.207037 [    0/60000]\n",
            "loss: 2.201976 [ 6400/60000]\n",
            "loss: 2.165751 [12800/60000]\n",
            "loss: 2.213141 [19200/60000]\n",
            "loss: 2.169955 [25600/60000]\n",
            "loss: 2.109786 [32000/60000]\n",
            "loss: 2.179661 [38400/60000]\n",
            "loss: 2.101140 [44800/60000]\n",
            "loss: 2.110944 [51200/60000]\n",
            "loss: 2.130359 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 45.9%, Avg loss: 0.032673 \n",
            "\n",
            "Epoch 2\n",
            "--------------------------------\n",
            "loss: 2.057757 [    0/60000]\n",
            "loss: 2.049021 [ 6400/60000]\n",
            "loss: 1.977344 [12800/60000]\n",
            "loss: 2.096293 [19200/60000]\n",
            "loss: 1.983731 [25600/60000]\n",
            "loss: 1.891560 [32000/60000]\n",
            "loss: 2.021235 [38400/60000]\n",
            "loss: 1.877508 [44800/60000]\n",
            "loss: 1.912287 [51200/60000]\n",
            "loss: 1.926715 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 47.2%, Avg loss: 0.029197 \n",
            "\n",
            "Epoch 3\n",
            "--------------------------------\n",
            "loss: 1.816680 [    0/60000]\n",
            "loss: 1.803364 [ 6400/60000]\n",
            "loss: 1.697848 [12800/60000]\n",
            "loss: 1.894641 [19200/60000]\n",
            "loss: 1.723706 [25600/60000]\n",
            "loss: 1.614555 [32000/60000]\n",
            "loss: 1.788447 [38400/60000]\n",
            "loss: 1.617045 [44800/60000]\n",
            "loss: 1.672955 [51200/60000]\n",
            "loss: 1.671022 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.7%, Avg loss: 0.025448 \n",
            "\n",
            "Epoch 4\n",
            "--------------------------------\n",
            "loss: 1.562281 [    0/60000]\n",
            "loss: 1.560504 [ 6400/60000]\n",
            "loss: 1.444501 [12800/60000]\n",
            "loss: 1.691988 [19200/60000]\n",
            "loss: 1.499520 [25600/60000]\n",
            "loss: 1.399489 [32000/60000]\n",
            "loss: 1.573262 [38400/60000]\n",
            "loss: 1.420740 [44800/60000]\n",
            "loss: 1.468700 [51200/60000]\n",
            "loss: 1.457028 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.4%, Avg loss: 0.022480 \n",
            "\n",
            "Epoch 5\n",
            "--------------------------------\n",
            "loss: 1.361983 [    0/60000]\n",
            "loss: 1.380441 [ 6400/60000]\n",
            "loss: 1.258909 [12800/60000]\n",
            "loss: 1.534810 [19200/60000]\n",
            "loss: 1.328472 [25600/60000]\n",
            "loss: 1.247066 [32000/60000]\n",
            "loss: 1.414737 [38400/60000]\n",
            "loss: 1.285445 [44800/60000]\n",
            "loss: 1.326175 [51200/60000]\n",
            "loss: 1.317289 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.5%, Avg loss: 0.020375 \n",
            "\n",
            "Epoch 6\n",
            "--------------------------------\n",
            "loss: 1.217826 [    0/60000]\n",
            "loss: 1.257513 [ 6400/60000]\n",
            "loss: 1.124963 [12800/60000]\n",
            "loss: 1.425518 [19200/60000]\n",
            "loss: 1.208720 [25600/60000]\n",
            "loss: 1.139678 [32000/60000]\n",
            "loss: 1.308520 [38400/60000]\n",
            "loss: 1.193321 [44800/60000]\n",
            "loss: 1.230513 [51200/60000]\n",
            "loss: 1.227734 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 0.018927 \n",
            "\n",
            "Epoch 7\n",
            "--------------------------------\n",
            "loss: 1.118009 [    0/60000]\n",
            "loss: 1.176297 [ 6400/60000]\n",
            "loss: 1.029630 [12800/60000]\n",
            "loss: 1.349651 [19200/60000]\n",
            "loss: 1.128108 [25600/60000]\n",
            "loss: 1.063597 [32000/60000]\n",
            "loss: 1.236886 [38400/60000]\n",
            "loss: 1.129793 [44800/60000]\n",
            "loss: 1.164346 [51200/60000]\n",
            "loss: 1.168581 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.9%, Avg loss: 0.017914 \n",
            "\n",
            "Epoch 8\n",
            "--------------------------------\n",
            "loss: 1.045872 [    0/60000]\n",
            "loss: 1.119269 [ 6400/60000]\n",
            "loss: 0.960023 [12800/60000]\n",
            "loss: 1.295853 [19200/60000]\n",
            "loss: 1.072603 [25600/60000]\n",
            "loss: 1.008894 [32000/60000]\n",
            "loss: 1.187573 [38400/60000]\n",
            "loss: 1.084307 [44800/60000]\n",
            "loss: 1.116722 [51200/60000]\n",
            "loss: 1.128299 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 59.9%, Avg loss: 0.017180 \n",
            "\n",
            "Epoch 9\n",
            "--------------------------------\n",
            "loss: 0.989788 [    0/60000]\n",
            "loss: 1.076547 [ 6400/60000]\n",
            "loss: 0.906451 [12800/60000]\n",
            "loss: 1.255456 [19200/60000]\n",
            "loss: 1.031807 [25600/60000]\n",
            "loss: 0.967148 [32000/60000]\n",
            "loss: 1.150838 [38400/60000]\n",
            "loss: 1.049877 [44800/60000]\n",
            "loss: 1.078774 [51200/60000]\n",
            "loss: 1.097722 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.2%, Avg loss: 0.016605 \n",
            "\n",
            "Epoch 10\n",
            "--------------------------------\n",
            "loss: 0.943510 [    0/60000]\n",
            "loss: 1.042160 [ 6400/60000]\n",
            "loss: 0.863009 [12800/60000]\n",
            "loss: 1.222429 [19200/60000]\n",
            "loss: 0.999753 [25600/60000]\n",
            "loss: 0.933981 [32000/60000]\n",
            "loss: 1.121490 [38400/60000]\n",
            "loss: 1.022035 [44800/60000]\n",
            "loss: 1.047166 [51200/60000]\n",
            "loss: 1.073031 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 0.016128 \n",
            "\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}