{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "computer_vision(test1).ipynb",
      "provenance": [],
      "mount_file_id": "1xjozSiyMRALqQP923K2SD15Zadj1tbf3",
      "authorship_tag": "ABX9TyNji4bnmiww9a4+fGGGQKx9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jisoolee11/AI_study/blob/main/computer_vision(test2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAY54iJiq_-B"
      },
      "source": [
        "<h1> DACON 제 2회 컴퓨터 비전 학습 경진대회"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNvvmhU1aUzg"
      },
      "source": [
        "# from google.colab import drive\r\n",
        "\r\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8WWj1XzbCZ3"
      },
      "source": [
        "# !unzip -qq /content/gdrive/My\\ Drive/data_2/mnist_data.zip\r\n",
        "# !unzip -qq /content/gdrive/MyDrive/data_2/test_dirty_mnist.zip\r\n",
        "# !unzip -qq /content/gdrive/MyDrive/data_2/dirty_mnist.zip"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNdARf1Iclgc"
      },
      "source": [
        "import os\r\n",
        "from typing import Tuple, Sequence, Callable\r\n",
        "import csv\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "import torch.optim as optim\r\n",
        "from torch import nn, Tensor\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchsummary import summary\r\n",
        "\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.models import resnet50"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp84hc0lcqr8"
      },
      "source": [
        "class MnistDataset(Dataset):\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        dir: os.PathLike,\r\n",
        "        image_ids: os.PathLike,\r\n",
        "        transforms: Sequence[Callable]\r\n",
        "    ) -> None:\r\n",
        "        self.dir = dir\r\n",
        "        self.transforms = transforms\r\n",
        "\r\n",
        "        self.labels = {}\r\n",
        "        with open(image_ids, 'r') as f:\r\n",
        "            reader = csv.reader(f)\r\n",
        "            next(reader)\r\n",
        "            for row in reader:\r\n",
        "                self.labels[int(row[0])] = list(map(int, row[1:]))\r\n",
        "\r\n",
        "        self.image_ids = list(self.labels.keys())\r\n",
        "\r\n",
        "    def __len__(self) -> int:\r\n",
        "        return len(self.image_ids)\r\n",
        "\r\n",
        "    def __getitem__(self, index: int) -> Tuple[Tensor]:\r\n",
        "        image_id = self.image_ids[index]\r\n",
        "        image = Image.open(\r\n",
        "            os.path.join(\r\n",
        "                self.dir, f'{str(image_id).zfill(5)}.png')).convert('RGB')\r\n",
        "        target = np.array(self.labels.get(image_id)).astype(np.float32)\r\n",
        "\r\n",
        "        if self.transforms is not None:\r\n",
        "            image = self.transforms(image)\r\n",
        "\r\n",
        "        return image, target"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TmU691FcuCn"
      },
      "source": [
        "transforms_train = transforms.Compose([\r\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\r\n",
        "    transforms.RandomVerticalFlip(p=0.5),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225]\r\n",
        "    )\r\n",
        "])\r\n",
        "\r\n",
        "transforms_test = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225]\r\n",
        "    )\r\n",
        "])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867XDQnYcxup"
      },
      "source": [
        "trainset = MnistDataset('/content', '/content/gdrive/MyDrive/data_2/dirty_mnist_answer.csv', transforms_train)\r\n",
        "testset = MnistDataset('/content', '/content/gdrive/MyDrive/data_2/sample_submission.csv', transforms_test)\r\n",
        "\r\n",
        "train_loader = DataLoader(trainset, batch_size=32, num_workers=2)\r\n",
        "test_loader = DataLoader(testset, batch_size=10, num_workers=1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GPLEvMEdHS6",
        "outputId": "cafba7a8-25d9-4f50-e91e-bb5942d019fa"
      },
      "source": [
        "class MnistModel(nn.Module):\r\n",
        "    def __init__(self) -> None:\r\n",
        "        super().__init__()\r\n",
        "        self.resnet = resnet50(pretrained=True)\r\n",
        "        self.classifier = nn.Linear(1000, 26)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.resnet(x)\r\n",
        "        x = self.classifier(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model = MnistModel().to(device)\r\n",
        "print(summary(model,(3, 256, 256)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "              ReLU-3         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
            "            Conv2d-5           [-1, 64, 64, 64]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "              ReLU-7           [-1, 64, 64, 64]               0\n",
            "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
            "             ReLU-10           [-1, 64, 64, 64]               0\n",
            "           Conv2d-11          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
            "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
            "             ReLU-15          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
            "           Conv2d-17           [-1, 64, 64, 64]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
            "             ReLU-19           [-1, 64, 64, 64]               0\n",
            "           Conv2d-20           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 64, 64]             128\n",
            "             ReLU-22           [-1, 64, 64, 64]               0\n",
            "           Conv2d-23          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
            "             ReLU-25          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
            "           Conv2d-27           [-1, 64, 64, 64]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 64, 64]             128\n",
            "             ReLU-29           [-1, 64, 64, 64]               0\n",
            "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 64, 64]             128\n",
            "             ReLU-32           [-1, 64, 64, 64]               0\n",
            "           Conv2d-33          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
            "             ReLU-35          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
            "           Conv2d-37          [-1, 128, 64, 64]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 64, 64]             256\n",
            "             ReLU-39          [-1, 128, 64, 64]               0\n",
            "           Conv2d-40          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 32, 32]             256\n",
            "             ReLU-42          [-1, 128, 32, 32]               0\n",
            "           Conv2d-43          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
            "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
            "           Conv2d-49          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 32, 32]             256\n",
            "             ReLU-51          [-1, 128, 32, 32]               0\n",
            "           Conv2d-52          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 32, 32]             256\n",
            "             ReLU-54          [-1, 128, 32, 32]               0\n",
            "           Conv2d-55          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-57          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
            "           Conv2d-59          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 32, 32]             256\n",
            "             ReLU-61          [-1, 128, 32, 32]               0\n",
            "           Conv2d-62          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 32, 32]             256\n",
            "             ReLU-64          [-1, 128, 32, 32]               0\n",
            "           Conv2d-65          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
            "           Conv2d-69          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 32, 32]             256\n",
            "             ReLU-71          [-1, 128, 32, 32]               0\n",
            "           Conv2d-72          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 32, 32]             256\n",
            "             ReLU-74          [-1, 128, 32, 32]               0\n",
            "           Conv2d-75          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-77          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
            "           Conv2d-79          [-1, 256, 32, 32]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 32, 32]             512\n",
            "             ReLU-81          [-1, 256, 32, 32]               0\n",
            "           Conv2d-82          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 16, 16]             512\n",
            "             ReLU-84          [-1, 256, 16, 16]               0\n",
            "           Conv2d-85         [-1, 1024, 16, 16]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
            "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-89         [-1, 1024, 16, 16]               0\n",
            "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-91          [-1, 256, 16, 16]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 16, 16]             512\n",
            "             ReLU-93          [-1, 256, 16, 16]               0\n",
            "           Conv2d-94          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 16, 16]             512\n",
            "             ReLU-96          [-1, 256, 16, 16]               0\n",
            "           Conv2d-97         [-1, 1024, 16, 16]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-99         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-101          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 16, 16]             512\n",
            "            ReLU-103          [-1, 256, 16, 16]               0\n",
            "          Conv2d-104          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 16, 16]             512\n",
            "            ReLU-106          [-1, 256, 16, 16]               0\n",
            "          Conv2d-107         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-109         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-111          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 16, 16]             512\n",
            "            ReLU-113          [-1, 256, 16, 16]               0\n",
            "          Conv2d-114          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 16, 16]             512\n",
            "            ReLU-116          [-1, 256, 16, 16]               0\n",
            "          Conv2d-117         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-119         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
            "            ReLU-123          [-1, 256, 16, 16]               0\n",
            "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
            "            ReLU-126          [-1, 256, 16, 16]               0\n",
            "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-129         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-131          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 16, 16]             512\n",
            "            ReLU-133          [-1, 256, 16, 16]               0\n",
            "          Conv2d-134          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 16, 16]             512\n",
            "            ReLU-136          [-1, 256, 16, 16]               0\n",
            "          Conv2d-137         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-139         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-141          [-1, 512, 16, 16]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-143          [-1, 512, 16, 16]               0\n",
            "          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-146            [-1, 512, 8, 8]               0\n",
            "          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n",
            "          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-151           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-152           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-155            [-1, 512, 8, 8]               0\n",
            "          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-158            [-1, 512, 8, 8]               0\n",
            "          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-161           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-162           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-165            [-1, 512, 8, 8]               0\n",
            "          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-168            [-1, 512, 8, 8]               0\n",
            "          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-171           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-172           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "          ResNet-175                 [-1, 1000]               0\n",
            "          Linear-176                   [-1, 26]          26,026\n",
            "================================================================\n",
            "Total params: 25,583,058\n",
            "Trainable params: 25,583,058\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 374.28\n",
            "Params size (MB): 97.59\n",
            "Estimated Total Size (MB): 472.62\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9by8o-KPdKbX",
        "outputId": "061d2ffc-4929-4f3e-e717-3ec4d3ad7a08"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\r\n",
        "\r\n",
        "num_epochs = 10\r\n",
        "model.train()\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (images, targets) in enumerate(train_loader):\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        images = images.to(device)\r\n",
        "        targets = targets.to(device)\r\n",
        "\r\n",
        "        outputs = model(images)\r\n",
        "        loss = criterion(outputs, targets)\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if (i+1) % 100 == 0:\r\n",
        "            outputs = outputs > 0.5\r\n",
        "            acc = (outputs == targets).float().mean()\r\n",
        "            print(f'{epoch}: {loss.item():.5f}, {acc.item():.5f}')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 0.04949, 0.97837\n",
            "0: 0.06716, 0.96995\n",
            "0: 0.06635, 0.97837\n",
            "0: 0.07441, 0.97236\n",
            "0: 0.07483, 0.96995\n",
            "0: 0.09036, 0.96755\n",
            "0: 0.10054, 0.96154\n",
            "0: 0.09255, 0.96394\n",
            "0: 0.08120, 0.97236\n",
            "0: 0.09483, 0.96995\n",
            "0: 0.07396, 0.96875\n",
            "0: 0.09620, 0.96034\n",
            "0: 0.07520, 0.97115\n",
            "0: 0.08369, 0.97115\n",
            "0: 0.06109, 0.97837\n",
            "1: 0.07438, 0.96755\n",
            "1: 0.08433, 0.96995\n",
            "1: 0.04085, 0.98317\n",
            "1: 0.10306, 0.95793\n",
            "1: 0.05688, 0.97957\n",
            "1: 0.06911, 0.97476\n",
            "1: 0.07164, 0.97476\n",
            "1: 0.10333, 0.96635\n",
            "1: 0.04968, 0.97957\n",
            "1: 0.05305, 0.98197\n",
            "1: 0.06703, 0.97596\n",
            "1: 0.07595, 0.96995\n",
            "1: 0.05618, 0.97957\n",
            "1: 0.06634, 0.97596\n",
            "1: 0.05184, 0.97476\n",
            "2: 0.08353, 0.96514\n",
            "2: 0.06103, 0.97596\n",
            "2: 0.06635, 0.97115\n",
            "2: 0.05933, 0.97957\n",
            "2: 0.06529, 0.97596\n",
            "2: 0.04504, 0.98077\n",
            "2: 0.07488, 0.97716\n",
            "2: 0.04782, 0.98317\n",
            "2: 0.06702, 0.97356\n",
            "2: 0.05574, 0.98317\n",
            "2: 0.04987, 0.98438\n",
            "2: 0.04397, 0.97837\n",
            "2: 0.04734, 0.98918\n",
            "2: 0.06779, 0.97476\n",
            "2: 0.05085, 0.97957\n",
            "3: 0.06521, 0.97716\n",
            "3: 0.04887, 0.98077\n",
            "3: 0.04442, 0.98317\n",
            "3: 0.03722, 0.98558\n",
            "3: 0.03164, 0.98798\n",
            "3: 0.04596, 0.98558\n",
            "3: 0.06088, 0.98317\n",
            "3: 0.06936, 0.97115\n",
            "3: 0.05309, 0.97837\n",
            "3: 0.04323, 0.98317\n",
            "3: 0.08459, 0.96995\n",
            "3: 0.05806, 0.97716\n",
            "3: 0.06614, 0.98197\n",
            "3: 0.03734, 0.98678\n",
            "3: 0.09682, 0.96635\n",
            "4: 0.06030, 0.98197\n",
            "4: 0.05436, 0.97957\n",
            "4: 0.03264, 0.99038\n",
            "4: 0.05460, 0.98317\n",
            "4: 0.05805, 0.98077\n",
            "4: 0.04544, 0.97957\n",
            "4: 0.04896, 0.98317\n",
            "4: 0.02278, 0.99038\n",
            "4: 0.04971, 0.98197\n",
            "4: 0.07874, 0.97236\n",
            "4: 0.04321, 0.98197\n",
            "4: 0.07100, 0.97957\n",
            "4: 0.03755, 0.98678\n",
            "4: 0.04830, 0.98558\n",
            "4: 0.05125, 0.97957\n",
            "5: 0.02461, 0.99279\n",
            "5: 0.06336, 0.98077\n",
            "5: 0.02920, 0.99038\n",
            "5: 0.07287, 0.98317\n",
            "5: 0.04154, 0.98438\n",
            "5: 0.04153, 0.98438\n",
            "5: 0.03901, 0.98438\n",
            "5: 0.08087, 0.97476\n",
            "5: 0.03824, 0.98678\n",
            "5: 0.03385, 0.98918\n",
            "5: 0.04597, 0.98438\n",
            "5: 0.03161, 0.98918\n",
            "5: 0.04750, 0.98678\n",
            "5: 0.02495, 0.98918\n",
            "5: 0.05578, 0.97957\n",
            "6: 0.03909, 0.98317\n",
            "6: 0.02443, 0.98918\n",
            "6: 0.03804, 0.99159\n",
            "6: 0.04362, 0.98438\n",
            "6: 0.02908, 0.99038\n",
            "6: 0.05623, 0.97957\n",
            "6: 0.03219, 0.98798\n",
            "6: 0.04071, 0.98438\n",
            "6: 0.04553, 0.98317\n",
            "6: 0.04527, 0.98558\n",
            "6: 0.04501, 0.98317\n",
            "6: 0.03807, 0.99038\n",
            "6: 0.15858, 0.93990\n",
            "6: 0.53769, 0.71875\n",
            "6: 0.20786, 0.90505\n",
            "7: 0.09753, 0.96875\n",
            "7: 0.08502, 0.96755\n",
            "7: 0.07322, 0.97356\n",
            "7: 0.04806, 0.98317\n",
            "7: 0.04524, 0.98678\n",
            "7: 0.04478, 0.98077\n",
            "7: 0.03764, 0.98918\n",
            "7: 0.03546, 0.98678\n",
            "7: 0.03458, 0.98678\n",
            "7: 0.03439, 0.98678\n",
            "7: 0.03745, 0.98678\n",
            "7: 0.03870, 0.98558\n",
            "7: 0.03433, 0.99038\n",
            "7: 0.04477, 0.98798\n",
            "7: 0.02189, 0.98918\n",
            "8: 0.02136, 0.99038\n",
            "8: 0.03427, 0.98798\n",
            "8: 0.02022, 0.99279\n",
            "8: 0.02613, 0.99279\n",
            "8: 0.03900, 0.98438\n",
            "8: 0.03410, 0.98197\n",
            "8: 0.02036, 0.99519\n",
            "8: 0.01829, 0.99519\n",
            "8: 0.02684, 0.98918\n",
            "8: 0.02975, 0.99279\n",
            "8: 0.02997, 0.98798\n",
            "8: 0.02781, 0.98798\n",
            "8: 0.02830, 0.98918\n",
            "8: 0.03352, 0.98798\n",
            "8: 0.03524, 0.98678\n",
            "9: 0.04054, 0.98678\n",
            "9: 0.05300, 0.98438\n",
            "9: 0.01193, 0.99760\n",
            "9: 0.02439, 0.99038\n",
            "9: 0.03745, 0.99159\n",
            "9: 0.02138, 0.99279\n",
            "9: 0.04152, 0.98918\n",
            "9: 0.01846, 0.99038\n",
            "9: 0.02058, 0.99399\n",
            "9: 0.02737, 0.99038\n",
            "9: 0.01745, 0.99159\n",
            "9: 0.02487, 0.98918\n",
            "9: 0.01064, 0.99639\n",
            "9: 0.03061, 0.98798\n",
            "9: 0.03530, 0.98438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsS8EBHannW3"
      },
      "source": [
        "submit = pd.read_csv('/content/gdrive/MyDrive/data_2/sample_submission.csv')\r\n",
        "\r\n",
        "model.eval()\r\n",
        "batch_size = test_loader.batch_size\r\n",
        "batch_index = 0\r\n",
        "for i, (images, targets) in enumerate(test_loader):\r\n",
        "    images = images.to(device)\r\n",
        "    targets = targets.to(device)\r\n",
        "    outputs = model(images)\r\n",
        "    outputs = outputs > 0.5\r\n",
        "    batch_index = i * batch_size\r\n",
        "    submit.iloc[batch_index:batch_index+batch_size, 1:] = \\\r\n",
        "        outputs.long().squeeze(0).detach().cpu().numpy()\r\n",
        "    \r\n",
        "submit.to_csv('/content/gdrive/MyDrive/Data/computer_vision/submit3.csv', index=False)\r\n",
        "\r\n",
        "\r\n",
        "# from google.colab import files\r\n",
        "\r\n",
        "# files.download('submit2.csv')"
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}
